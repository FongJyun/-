{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04b6e6cc",
   "metadata": {},
   "source": [
    "Project description\n",
    "\n",
    "License\n",
    "\n",
    "The code of InsightFace Python Library is released under the MIT License. There is no limitation for both academic and commercial usage.\n",
    "\n",
    "The pretrained models we provided with this library are available for non-commercial research purposes only, including both auto-downloading models and manual-downloading models.\n",
    "\n",
    "Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50600e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U insightface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5192439",
   "metadata": {},
   "source": [
    "Quick Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72a5888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "from insightface.data import get_image as ins_get_image\n",
    "\n",
    "app = FaceAnalysis()\n",
    "app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "img = ins_get_image('t1')\n",
    "faces = app.get(img)\n",
    "rimg = app.draw_on(img, faces)\n",
    "cv2.imwrite(\"./t1_output.jpg\", rimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a100de1",
   "metadata": {},
   "source": [
    "This quick example will detect faces from the t1.jpg image and draw detection results on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f87de2",
   "metadata": {},
   "source": [
    "Inference Backend\n",
    "For insightface<=0.1.5, we use MXNet as inference backend.\n",
    "\n",
    "(You may please download all models from onedrive, and put them all under ~/.insightface/models/ directory to use this old version)\n",
    "\n",
    "Starting from insightface>=0.2, we use onnxruntime as inference backend.\n",
    "\n",
    "(You have to install onnxruntime-gpu to enable GPU inference)\n",
    "\n",
    "Model Zoo\n",
    "In the latest version of insightface library, we provide following model packs:\n",
    "\n",
    "Name in bold is the default model pack.\n",
    "\n",
    "https://pypi.org/project/insightface/\n",
    "\n",
    "Name\tMR-AL L\tAfrica n\tCaucasia n\tSouth Asian\tEast Asian\tLFW\tCFP-F P\tAgeDB-3 0\tIJB-C(E4 )\n",
    "buffalo_l\t91.25\t90.29\t94.70\t93.16\t74.96\t99.8 3\t99.33\t98.23\t97.25\n",
    "buffalo_s\t71.87\t69.45\t80.45\t73.39\t51.03\t99.7 0\t98.00\t96.58\t95.02\n",
    "buffalo_m has the same accuracy with buffalo_l.\n",
    "\n",
    "buffalo_sc has the same accuracy with buffalo_s.\n",
    "\n",
    "Note that these models are available for non-commercial research purposes only.\n",
    "\n",
    "For insightface>=0.3.3, models will be downloaded automatically once we init app = FaceAnalysis() instance.\n",
    "\n",
    "For insightface==0.3.2, you must first download the model package by command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc4ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "insightface-cli model.download antelope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949bcf48",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c94875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "insightface-cli model.download antelopev2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23546f70",
   "metadata": {},
   "source": [
    "Use Your Own Licensed Model\n",
    "\n",
    "You can simply create a new model directory under ~/.insightface/models/ and replace the pretrained models we provide with your own models. And then call app = FaceAnalysis(name='your_model_zoo') to load these models.\n",
    "\n",
    "Call Models\n",
    "\n",
    "The latest insightface libary only supports onnx models. Once you have trained detection or recognition models by PyTorch, MXNet or any other frameworks, you can convert it to the onnx format and then they can be called with insightface library.\n",
    "\n",
    "Call Detection Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa595b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "from insightface.data import get_image as ins_get_image\n",
    "\n",
    "# Method-1, use FaceAnalysis\n",
    "app = FaceAnalysis(allowed_modules=['detection']) # enable detection model only\n",
    "app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "# Method-2, load model directly\n",
    "detector = insightface.model_zoo.get_model('your_detection_model.onnx')\n",
    "detector.prepare(ctx_id=0, det_size=(640, 640))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f31653",
   "metadata": {},
   "source": [
    "Call Recognition Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a64148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "from insightface.data import get_image as ins_get_image\n",
    "\n",
    "handler = insightface.model_zoo.get_model('your_recognition_model.onnx')\n",
    "handler.prepare(ctx_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31a10b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Organization  : insightface.ai\n",
    "# @Author        : Jia Guo\n",
    "# @Time          : 2021-05-04\n",
    "# @Function      : \n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import glob\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "from numpy.linalg import norm\n",
    "\n",
    "from ..model_zoo import model_zoo\n",
    "from ..utils import DEFAULT_MP_NAME, ensure_available\n",
    "from .common import Face\n",
    "\n",
    "__all__ = ['FaceAnalysis']\n",
    "\n",
    "class FaceAnalysis:\n",
    "    def __init__(self, name=DEFAULT_MP_NAME, root='~/.insightface', allowed_modules=None, **kwargs):\n",
    "        onnxruntime.set_default_logger_severity(3)\n",
    "        self.models = {}\n",
    "        self.model_dir = ensure_available('models', name, root=root)\n",
    "        onnx_files = glob.glob(osp.join(self.model_dir, '*.onnx'))\n",
    "        onnx_files = sorted(onnx_files)\n",
    "        for onnx_file in onnx_files:\n",
    "            model = model_zoo.get_model(onnx_file, **kwargs)\n",
    "            if model is None:\n",
    "                print('model not recognized:', onnx_file)\n",
    "            elif allowed_modules is not None and model.taskname not in allowed_modules:\n",
    "                print('model ignore:', onnx_file, model.taskname)\n",
    "                del model\n",
    "            elif model.taskname not in self.models and (allowed_modules is None or model.taskname in allowed_modules):\n",
    "                print('find model:', onnx_file, model.taskname, model.input_shape, model.input_mean, model.input_std)\n",
    "                self.models[model.taskname] = model\n",
    "            else:\n",
    "                print('duplicated model task type, ignore:', onnx_file, model.taskname)\n",
    "                del model\n",
    "        assert 'detection' in self.models\n",
    "        self.det_model = self.models['detection']\n",
    "\n",
    "\n",
    "    def prepare(self, ctx_id, det_thresh=0.5, det_size=(640, 640)):\n",
    "        self.det_thresh = det_thresh\n",
    "        assert det_size is not None\n",
    "        print('set det-size:', det_size)\n",
    "        self.det_size = det_size\n",
    "        for taskname, model in self.models.items():\n",
    "            if taskname=='detection':\n",
    "                model.prepare(ctx_id, input_size=det_size, det_thresh=det_thresh)\n",
    "            else:\n",
    "                model.prepare(ctx_id)\n",
    "\n",
    "    def get(self, img, max_num=0):\n",
    "        bboxes, kpss = self.det_model.detect(img,\n",
    "                                             max_num=max_num,\n",
    "                                             metric='default')\n",
    "        if bboxes.shape[0] == 0:\n",
    "            return []\n",
    "        ret = []\n",
    "        for i in range(bboxes.shape[0]):\n",
    "            bbox = bboxes[i, 0:4]\n",
    "            det_score = bboxes[i, 4]\n",
    "            kps = None\n",
    "            if kpss is not None:\n",
    "                kps = kpss[i]\n",
    "            face = Face(bbox=bbox, kps=kps, det_score=det_score)\n",
    "            for taskname, model in self.models.items():\n",
    "                if taskname=='detection':\n",
    "                    continue\n",
    "                model.get(img, face)\n",
    "            ret.append(face)\n",
    "        return ret\n",
    "\n",
    "    def draw_on(self, img, faces):\n",
    "        import cv2\n",
    "        dimg = img.copy()\n",
    "        for i in range(len(faces)):\n",
    "            face = faces[i]\n",
    "            box = face.bbox.astype(np.int)\n",
    "            color = (0, 0, 255)\n",
    "            cv2.rectangle(dimg, (box[0], box[1]), (box[2], box[3]), color, 2)\n",
    "            if face.kps is not None:\n",
    "                kps = face.kps.astype(np.int)\n",
    "                #print(landmark.shape)\n",
    "                for l in range(kps.shape[0]):\n",
    "                    color = (0, 0, 255)\n",
    "                    if l == 0 or l == 3:\n",
    "                        color = (0, 255, 0)\n",
    "                    cv2.circle(dimg, (kps[l][0], kps[l][1]), 1, color,\n",
    "                               2)\n",
    "            if face.gender is not None and face.age is not None:\n",
    "                cv2.putText(dimg,'%s,%d'%(face.sex,face.age), (box[0]-1, box[1]-4),cv2.FONT_HERSHEY_COMPLEX,0.7,(0,255,0),1)\n",
    "\n",
    "            #for key, value in face.items():\n",
    "            #    if key.startswith('landmark_3d'):\n",
    "            #        print(key, value.shape)\n",
    "            #        print(value[0:10,:])\n",
    "            #        lmk = np.round(value).astype(np.int)\n",
    "            #        for l in range(lmk.shape[0]):\n",
    "            #            color = (255, 0, 0)\n",
    "            #            cv2.circle(dimg, (lmk[l][0], lmk[l][1]), 1, color,\n",
    "            #                       2)\n",
    "        return dimg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myPython3",
   "language": "python",
   "name": "mypython3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
